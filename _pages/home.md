---
layout: default2
title: home
permalink: /
title: <h3  align="center">Second Workshop on CustomNLP4U</h3>
nav_order: 1
---


<!-- <html lang="en">
<div class="news-box">
  <h4>Announcements</h4>
  <br>
  <p>1. <b>Recordings</b> are available on the <a href="https://neurips.cc/virtual/2023/workshop/66498" target="_blank">NeurIPS website</a> (NeurIPS registration required). They will be made public after one month (Jan 2024).<br>
  2. <b>Talk slides</b> are posted on the <a href="/speakers">speakers page</a>.<br>
  3. Congratuations to <a href="#paper-awards">paper award winners</a>!<br>
  4. <b>Workshop highlights and photos</b> can be found on our <a href="https://twitter.com/itif_workshop">Twitter</a>.
  <br><br>
  Thank you for joining us at NeurIPS 2023! Hope to see you next time! 
  </p>
</div>
</html> -->

# Call for Papers
<br>
### Important Dates

All deadlines are 11:59 PM AoE (Anywhere on Earth) time.

* Submission Portal: TBD
* Submission Deadline: April 3, 2026
* Notification of Acceptance: May 25, 2026
* Camera-ready papers due: TBD
* Workshop Date and Time: July 3, 2026 (9:00 AM - 12:30 PM PT)
<br>

### Topics of Interest

Most language modeling research today is focused on building generalist models capable of solving a wide range of tasks with the recipe of pretraining at scale, and reinforcement learning based post-training. The increased capabilities of large language models (LLMs) have promised increased productivity and innovation [1] and seen broad consumption by an ever-widening audience for personal and commercial use [2]. However, users' expectations, values, and workflows can vary significantly across domains, applications, organizations, geography, social groups, cultures, and individuals. Attention to these factors is often missing or under-considered in existing Language Modeling pipelines. Specifically, generalist models have non-uniform performance, for example, for consumers working in sensitive and specialized domains such as law, finance, or health [3, 4]; for individuals, demographics, or cultures less represented online such as speakers of different language varieties [5]. For language models to deliver on their promise of productivity and innovation, particularly in emerging scenarios with widely varying use cases, there is a need to develop models that can be tailored to different consumers (individuals, groups, or organizations), easily controlled by them, and learn over time [6, 7]; models that can reason about their users' private knowledge and context to provide personalized responses [8, 9].
Alongside methodological questions, model customization raises ethical and security questions, related to learning from copyrighted data, protecting user privacy, and addressing pernicious biases. This is especially relevant in sensitive domains, where model customization can lead to large benefits for stakeholders but is also associated with higher risks.

The topics of this workshop include (but not limited to): 

* **Data**: Data collection, processing, and annotation to aid model customization; analysis of public and private datasets to guide the development of customized models; privacy, and copyright.
* **Modeling**: New pretraining, fine-tuning, alignment, continuous learning, inference methods for customizing language models; privacy and efficiency for customization. New modeling paradigms for customization such as model ensembles, federated learning, nonparametric models, etc.; customizing models with agentic systems, test-time compute strategies, etc.
* **Evaluation** of generalist, non-customized models, identifying their shortcomings for varied use-cases; evaluation of customized models.
* **Applications**: e.g. information seeking, writing assistance, AI assistants etc.; applications in sensitive domains such as law, education, healthcare, finance, etc.; models for communities reflecting sociolects, dialects or other language varieties.
* **Broader Impacts**: privacy, security, and copyright; intrusiveness, unintended biases; invisibility versus hypervisibility due to customization.
* **Open Science**: Best practices for open and reproducible science of customizable LMs: dataset release and licensing, open-sourcing models, related privacy, copyright and policy issues.
<br>

### Guidelines

* Our author guidelines follow the ARR requirements unless otherwise specified.
* Paper submission is hosted on [OpenReview](https://openreview.net/group?id=ACL/2026/Workshop/CustomNLP4U&referrer=%5BHomepage%5D(%2F)#tab-your-consoles).
* We welcome both short (__up to 4 pages__) and long papers (__up to 8 pages__), not including references or appendix. 
  * Please use the provided LaTex template ([Overleaf](https://www.overleaf.com/latex/templates/association-for-computational-linguistics-acl-conference/jvxskxpnznfj)) for your submission. Please follow the paper formatting guidelines general to “*ACL” conferences as specified in the style files. Authors may not modify the style files or use templates designed for other conferences.
  * The paper should be anonymized and uploaded to OpenReview as a single PDF. 
  * You may use as many pages of references and appendix as you wish, but reviewers are not required to read the appendix. 
  * Posting papers on preprint servers like ArXiv is permitted.
  * We encourage each submission to discuss the ethical and societal implications of their work, wherever applicable. 

* This workshop offers both archival and non-archival options for submissions. Archival papers will be indexed with proceedings, while non-archival submissions will not.
* The review process will be double-blind.
<br>

### References

[1] Singla, A., Sukharevsky, A., Berteletti, E., Yee, L., & Chui, M. (2025). The next innovation revolution—powered by AI. McKinsey & Company. https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-next-innovation-revolution-powered-by-ai

[2] Liang, W., Zhang, Y., Codreanu, M., Wang, J., Cao, H., & Zou, J. (2025). The Widespread Adoption of Large Language Model-Assisted Writing Across Society. arXiv preprint arXiv:2502.09747.

[3] Mahari, R., Stammbach, D., Ash, E., & Pentland, A. (2023). The Law and NLP: Bridging Disciplinary Disconnects. In Findings of the Association for Computational Linguistics: EMNLP 2023. Association for Computational Linguistics.

[4] Tam, T. Y. C., Sivarajkumar, S., Kapoor, S., Stolyar, A. V., Polanska, K., McCarthy, K. R., Osterhoudt, H., Wu, X., Visweswaran, S., Fu, S., et al. (2024). A Framework for Human Evaluation of Large Language Models in Healthcare Derived from Literature Review. NPJ digital medicine, 7(1), 258.

[5] Rystrøm, J., Kirk, H. R., & Hale, S. (2025). Multilingual != Multicultural: Evaluating Gaps Between Multilingual Capabilities and Cultural Alignment in LLMs. arXiv preprint arXiv:2502.16534.

[6] Narayanan, A., & Kapoor, S. (2025). AI as Normal Technology. Knight First Amend. Inst.

[7] Challapally, A., Pease, C., Raskar, R., & Chari, P. (2025). The GenAI Divide: State of AI in Business 2025. https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf

[8] Mireshghallah, N., Kim, H., Zhou, X., Tsvetkov, Y., Sap, M., Shokri, R., & Choi, Y. (2024). Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory. In The Twelfth International Conference on Learning Representations.

[9] Sorensen, T., Moore, J., Fisher, J., Gordon, M. L., Mireshghallah, N., Rytting, C. M., Ye, A., Jiang, L., Lu, X., Dziri, N., Althoff, T., & Choi, Y. (2024). Position: A Roadmap to Pluralistic Alignment. In Forty-first International Conference on Machine Learning.

<br>

## Organizers
<html>
    <div class="team-container">
        <div class="team-member">
            <img src="/assets/img/organizers/sheshera.jpg" alt="Name 1">
            <a href="https://msheshera.github.io/">Sheshera Mysore</a>
            <p>Office of Applied Research, Microsoft</p>
        </div>
        <div class="team-member">
            <img src="/assets/img/organizers/sachin.png" alt="Name 1">
            <a href="https://sites.google.com/view/sachinkumar">Sachin Kumar</a>
            <p>The Ohio State University, Allen Institute for AI</p>
        </div>
        <div class="team-member">
            <img src="/assets/img/organizers/vidhisha.jpg" alt="Name 4">
            <p><a href="https://vidhishanair.github.io/">Vidhisha Balachandran</a>
            <br>Microsoft Research</p>
        </div>
        <div class="team-member">
            <img src="/assets/img/organizers/shirley.jpeg" alt="Name 5">
            <p><a href="https://www.shirley.id/">Shirley Anugrah Hayati</a>
            <br>University of Minnesota</p>
        </div>
        <div class="team-member">
            <img src="/assets/img/organizers/faeze.jpg" alt="Name 5">
            <p><a href="https://fabrahman.github.io/">Faeze Brahman</a>
            <br>Allen Institute for AI</p>
        </div>
        <div class="team-member">
            <img src="/assets/img/organizers/hanane.jpg" alt="Name 5">
            <p><a href="https://sites.google.com/view/hananenourmoussa">Hanane Nour Moussa</a>
            <br>The Ohio State University</p>
        </div>
        </div>
</html>
<br>


## Steering Committee
<html>
    <div class="team-container">
        <div class="team-member">
            <img src="/assets/img/organizers/hamed.jpg" alt="Name 2">
            <p><a href="https://groups.cs.umass.edu/zamani/">Hamed Zamani</a>
            <br>University of Massachusetts Amherst</p>
        </div>
        <div class="team-member">
            <img src="/assets/img/organizers/dykang.jpg" alt="Name 2">
            <p><a href="https://dykang.github.io/">Dongyeop Kang</a>
            <br>University of Minnesota</p>
        </div>
        <div class="team-member">
            <img src="/assets/img/organizers/yulia.jpg" alt="Name 1">
            <a href="https://homes.cs.washington.edu/~yuliats/">Yulia Tsvetkov</a>
            <p>University of Washington</p>
        </div>
        </div>
</html>

<style>
    /* Style for the team container */
.team-container {
    display: grid;
    grid-template-columns: repeat(5, 1fr); /* Display 3 members per row */
    gap: 5px;
    max-width: 1000px;
    padding: 20px;
}

@media (max-width: 768px) {
    .team-container {
        grid-template-columns: repeat(2, 1fr); /* Display 2 members per row on smaller screens */
    }
}

/* Style for each team member */
.team-member {
    text-align: center;
    background-color: #fff;
    padding: 0px;
    width: 150px; /* Set a fixed width for consistent circle appearance */
    height: 260px; /* Set a fixed height for consistent circle appearance */
    /* box-shadow: 0px 3px 6px rgba(0, 0, 0, 0.1); */
    overflow: hidden; /* Hide any image overflow */
}


.team-member h3 {
    font-size: 16px;
    color: #333;
}

.team-member img {
  object-fit: cover;
  border-radius:50%;
  width: 150px;
  height: 150px;
  padding: 10px;
}

.sponsor-container {
    display: flex;
    gap: 5px;
}

.sponsor {
    flex: 1;
    margin: 10px;
    text-align: center;
    box-sizing: border-box;
    height: 50px;
    width: 50px;
}

.sponsor img {  
    width: 100%; /* Make the image take up 100% of the figure's width */
    height: 100%;
    object-fit: contain; 
}

.caption {
    margin-top: 12px; /* Adjust the margin to control the gap between the figure and the caption */
}

.right-half {
    flex: 1; /* Each figure takes up 50% of the available width */
    height: 500px; /* Set a fixed height for all figures (adjust the value as needed) */
}

.news-box {
    border: 1px solid #ccc;
    padding: 10px;
    width: 600px;
    margin: 0 auto;
    background-color: #f9f9f9;
}

@media (max-width: 600px) {
    .news-box {
        width: 100%; /* Adjust width to fit the screen */
    }
}
</style>

<br><br> 